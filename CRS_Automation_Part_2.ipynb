{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNktI3hXwnzs0MG+zXC4mzR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppthaw2024/Kristal-Transaction-Monitoring/blob/main/CRS_Automation_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Not counting the Number of Joint Holders\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ---------- Paths ----------\n",
        "raw_path = '/content/crs_export_KASG.xlsx'\n",
        "template_path = '/content/KAMEL - CRS Submission.xlsx'\n",
        "\n",
        "# ---------- Load data ----------\n",
        "raw_data = pd.read_excel(raw_path, sheet_name=0)\n",
        "# If your template has a title row, header=1 captures the actual headers\n",
        "template  = pd.read_excel(template_path, sheet_name='Accounts', header=1)\n",
        "required_columns = list(template.columns)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def safe_series(df, col, default=\"\"):\n",
        "    return df[col] if col in df.columns else pd.Series([default] * len(df), index=df.index)\n",
        "\n",
        "def concat_with_sep(sep, *series_list):\n",
        "    parts = []\n",
        "    for s in series_list:\n",
        "        s_clean = s.astype(str).str.strip().replace({\"nan\": \"\", \"None\": \"\"})\n",
        "        s_clean = s_clean.mask(s_clean.eq(\"\"))  # empty -> NaN\n",
        "        parts.append(s_clean)\n",
        "    stacked = pd.concat(parts, axis=1)\n",
        "    return stacked.apply(lambda r: sep.join([x for x in r.dropna().astype(str)]), axis=1).fillna(\"\")\n",
        "\n",
        "def sum_numeric(*series_list):\n",
        "    total = pd.Series(0.0, index=series_list[0].index, dtype=\"float64\")\n",
        "    for s in series_list:\n",
        "        total = total.add(pd.to_numeric(s, errors=\"coerce\").fillna(0.0), fill_value=0.0)\n",
        "    return total\n",
        "\n",
        "def parse_date(series, fmt_out=\"%d/%m/%Y\"):\n",
        "    parsed = pd.to_datetime(series, errors=\"coerce\")\n",
        "    out = pd.Series(\"\", index=series.index, dtype=\"object\")\n",
        "    mask = parsed.notna()\n",
        "    out.loc[mask] = parsed.loc[mask].dt.strftime(fmt_out)\n",
        "    out.loc[~mask] = series.astype(str).where(~series.isna(), \"\")\n",
        "    return out\n",
        "\n",
        "def clean_tin_preserve(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Preserve TIN exactly unless it is empty/NaN or all zeros -> '0'.\n",
        "    Handles numeric-looking inputs like 12345.0 -> '12345'.\n",
        "    \"\"\"\n",
        "    def norm(v):\n",
        "        if pd.isna(v):\n",
        "            return \"0\"\n",
        "        if isinstance(v, (int, np.integer)):\n",
        "            s = str(v)\n",
        "        elif isinstance(v, float):\n",
        "            if np.isfinite(v) and v.is_integer():\n",
        "                s = str(int(v))\n",
        "            else:\n",
        "                s = str(v)\n",
        "        else:\n",
        "            s = str(v)\n",
        "        s = s.strip()\n",
        "        if s == \"\" or s.lower() in (\"nan\", \"none\"):\n",
        "            return \"0\"\n",
        "        # zeros-only string -> \"0\"\n",
        "        if len(s) > 0 and set(s) <= {\"0\"}:\n",
        "            return \"0\"\n",
        "        return s\n",
        "    return series.apply(norm).astype(str)\n",
        "\n",
        "# ---------- Mapping spec ----------\n",
        "# kinds: \"copy\", \"concat\", \"const\", \"date\", \"sum\", \"tin_keep\"\n",
        "mapping_spec = {\n",
        "    \"Number\": (\"copy\", [\"application_id\"]),\n",
        "    \"Holder Individual\": (\"copy\", [\"client_id\"]),\n",
        "    \"Holder Entity\": (\"copy\", [\"controlling_client_id\"]),\n",
        "\n",
        "    \"First Name\": (\"copy\", [\"first_name\"]),\n",
        "    \"Last Name\":  (\"copy\", [\"last_name\"]),\n",
        "\n",
        "    # Street = address_1 + address_2 with comma only when both exist\n",
        "    \"Street\": (\"concat\", [\"residential_address_1\", \"residential_address_2\"], {\"sep\": \", \"}),\n",
        "\n",
        "    \"City\": (\"copy\", [\"residential_city\"]),\n",
        "    \"Country\": (\"copy\", [\"country_of_residence\"]),\n",
        "    \"Postal Code\": (\"copy\", [\"residential_postal_code\"]),\n",
        "\n",
        "    # TIN rule: preserve exactly unless empty/NaN/zeros-only -> '0'\n",
        "    \"TIN 1\": (\"tin_keep\", [\"primary_tax_id\"]),\n",
        "    \"TIN Issuer 1\": (\"copy\", [\"primary_tax_country\"]),\n",
        "    \"Tax Residency 1\": (\"copy\", [\"primary_tax_country\"]),\n",
        "\n",
        "    # DOB -> dd/mm/YYYY\n",
        "    \"Date of Birth\": (\"date\", [\"date_of_birth\"], {\"fmt\": \"%d/%m/%Y\"}),\n",
        "\n",
        "    # Business rules\n",
        "    \"Currency\": (\"const\", \"USD\"),\n",
        "    \"Type\": (\"copy\", [\"booking_center\"]),\n",
        "    \"Number Type\": (\"copy\", [\"client_type\"]),\n",
        "\n",
        "    # Choose one for Balance:\n",
        "    \"Balance\": (\"copy\", [\"cash_balance\"]),\n",
        "    # Or: \"Balance\": (\"sum\", [\"application_aum\", \"cash_balance\"]),\n",
        "}\n",
        "\n",
        "# ---------- Build submission in template order ----------\n",
        "submission_df = pd.DataFrame(index=raw_data.index)\n",
        "\n",
        "for tgt in required_columns:\n",
        "    spec = mapping_spec.get(tgt)\n",
        "    if not spec:\n",
        "        submission_df[tgt] = \"\"  # unmapped targets left blank\n",
        "        continue\n",
        "\n",
        "    kind = spec[0]\n",
        "    sources = spec[1] if len(spec) > 1 else []\n",
        "    opts = spec[2] if len(spec) > 2 else {}\n",
        "\n",
        "    if kind == \"copy\":\n",
        "        submission_df[tgt] = safe_series(raw_data, sources[0]).astype(str).str.strip()\n",
        "\n",
        "    elif kind == \"concat\":\n",
        "        series_list = [safe_series(raw_data, s).astype(str) for s in sources]\n",
        "        submission_df[tgt] = concat_with_sep(opts.get(\"sep\", \" \"), *series_list)\n",
        "\n",
        "    elif kind == \"const\":\n",
        "        value = spec[1] if isinstance(spec[1], str) else opts\n",
        "        submission_df[tgt] = pd.Series([value]*len(raw_data), index=raw_data.index)\n",
        "\n",
        "    elif kind == \"date\":\n",
        "        fmt = opts.get(\"fmt\", \"%d/%m/%Y\")\n",
        "        submission_df[tgt] = parse_date(safe_series(raw_data, sources[0]), fmt_out=fmt)\n",
        "\n",
        "    elif kind == \"sum\":\n",
        "        series_list = [safe_series(raw_data, s, default=0) for s in sources]\n",
        "        submission_df[tgt] = sum_numeric(*series_list).round(2)\n",
        "\n",
        "    elif kind == \"tin_keep\":\n",
        "        submission_df[tgt] = clean_tin_preserve(safe_series(raw_data, sources[0]))\n",
        "\n",
        "    else:\n",
        "        submission_df[tgt] = \"\"\n",
        "\n",
        "# Keep exact template order\n",
        "submission_df = submission_df.reindex(columns=required_columns)\n",
        "\n",
        "# ---------- Entity name rule: move to \"Name\" instead of First/Last ----------\n",
        "# If raw Last Name equals one of these tokens (case-insensitive), treat as entity.\n",
        "ENTITY_LASTNAME_TOKENS = {\n",
        "    \"PTE LTD\", \"SN ISSUER AND BROKER\", \"LIMITED\", \"FUND MANAGER\", \"ISSUER\",\n",
        "    \"CMA ACC PROVIDER\", \"COUNTERPARTY\", \"PVT MKT COUNTERPARTY\", \"CLIENT\",\n",
        "    \"HOLDING LIMITED\", \"INTERNATIONAL TRUST\"\n",
        "}\n",
        "\n",
        "# Build a mask from RAW last_name (not the mapped one) for strict equality with the tokens.\n",
        "last_raw_norm = safe_series(raw_data, \"last_name\").astype(str).str.strip().str.upper()\n",
        "entity_mask = last_raw_norm.isin(ENTITY_LASTNAME_TOKENS)\n",
        "\n",
        "# If \"Name\" exists in template, set Name = \"First Name + Last Name\" (only for entity rows)\n",
        "if \"Name\" in submission_df.columns:\n",
        "    fn = submission_df.get(\"First Name\", pd.Series(\"\", index=submission_df.index)).astype(str)\n",
        "    ln = submission_df.get(\"Last Name\",  pd.Series(\"\", index=submission_df.index)).astype(str)\n",
        "    full_name = concat_with_sep(\" \", fn, ln)\n",
        "    # populate Name only where entity_mask is True\n",
        "    submission_df.loc[entity_mask, \"Name\"] = full_name.loc[entity_mask]\n",
        "\n",
        "# Blank out First/Last where entity_mask is True (since we moved it to Name)\n",
        "if \"First Name\" in submission_df.columns:\n",
        "    submission_df.loc[entity_mask, \"First Name\"] = \"\"\n",
        "if \"Last Name\" in submission_df.columns:\n",
        "    submission_df.loc[entity_mask, \"Last Name\"] = \"\"\n",
        "\n",
        "# ---------- Optional clean-ups ----------\n",
        "# Postal code: numeric-only and zero-pad to 6 (SG style)\n",
        "if \"Postal Code\" in submission_df.columns:\n",
        "    submission_df[\"Postal Code\"] = (\n",
        "        submission_df[\"Postal Code\"].astype(str)\n",
        "        .str.replace(r\"\\D\", \"\", regex=True)\n",
        "        .str.zfill(6)\n",
        "    )\n",
        "\n",
        "# Is Joint? based on Number starting with J (only if present in template)\n",
        "if \"Is Joint?\" in submission_df.columns:\n",
        "    number_src = submission_df.get(\"Number\", pd.Series(\"\", index=submission_df.index)).astype(str).str.strip().str.upper()\n",
        "    submission_df[\"Is Joint?\"] = np.where(number_src.str.startswith(\"J\"), \"T\", \"F\")\n",
        "\n",
        "# ---------- Save ----------\n",
        "out_path = 'submission_ready.xlsx'\n",
        "submission_df.to_excel(out_path, index=False)\n",
        "print(f\"Saved: {out_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZCZSgO2RRGp",
        "outputId": "5daed8e4-7472-4fc8-ddae-7c8803c7e14e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: submission_ready.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting the number of Joint Holders. Should be lesser Rows\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ---------- Paths ----------\n",
        "raw_path = '/content/crs_export_KASG.xlsx'\n",
        "template_path = '/content/KAMEL - CRS Submission.xlsx'\n",
        "\n",
        "# ---------- Load data ----------\n",
        "raw_data = pd.read_excel(raw_path, sheet_name=0)\n",
        "# If the template has a title row, header=1 captures the actual headers\n",
        "template  = pd.read_excel(template_path, sheet_name='Accounts', header=1)\n",
        "required_columns = list(template.columns)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def safe_series(df, col, default=\"\"):\n",
        "    return df[col] if col in df.columns else pd.Series([default] * len(df), index=df.index)\n",
        "\n",
        "def concat_with_sep(sep, *series_list):\n",
        "    parts = []\n",
        "    for s in series_list:\n",
        "        s_clean = s.astype(str).str.strip().replace({\"nan\": \"\", \"None\": \"\"})\n",
        "        s_clean = s_clean.mask(s_clean.eq(\"\"))  # empty -> NaN\n",
        "        parts.append(s_clean)\n",
        "    stacked = pd.concat(parts, axis=1)\n",
        "    return stacked.apply(lambda r: sep.join([x for x in r.dropna().astype(str)]), axis=1).fillna(\"\")\n",
        "\n",
        "def sum_numeric(*series_list):\n",
        "    total = pd.Series(0.0, index=series_list[0].index, dtype=\"float64\")\n",
        "    for s in series_list:\n",
        "        total = total.add(pd.to_numeric(s, errors=\"coerce\").fillna(0.0), fill_value=0.0)\n",
        "    return total\n",
        "\n",
        "def parse_date(series, fmt_out=\"%d/%m/%Y\"):\n",
        "    parsed = pd.to_datetime(series, errors=\"coerce\")\n",
        "    out = pd.Series(\"\", index=series.index, dtype=\"object\")\n",
        "    mask = parsed.notna()\n",
        "    out.loc[mask] = parsed.loc[mask].dt.strftime(fmt_out)\n",
        "    out.loc[~mask] = series.astype(str).where(~series.isna(), \"\")\n",
        "    return out\n",
        "\n",
        "def clean_tin_preserve(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Preserve TIN exactly unless it is empty/NaN or all zeros -> '0'.\n",
        "    Handles numeric-looking inputs like 12345.0 -> '12345'.\n",
        "    \"\"\"\n",
        "    def norm(v):\n",
        "        if pd.isna(v):\n",
        "            return \"0\"\n",
        "        if isinstance(v, (int, np.integer)):\n",
        "            s = str(v)\n",
        "        elif isinstance(v, float):\n",
        "            if np.isfinite(v) and v.is_integer():\n",
        "                s = str(int(v))\n",
        "            else:\n",
        "                s = str(v)\n",
        "        else:\n",
        "            s = str(v)\n",
        "        s = s.strip()\n",
        "        if s == \"\" or s.lower() in (\"nan\", \"none\"):\n",
        "            return \"0\"\n",
        "        if len(s) > 0 and set(s) <= {\"0\"}:  # zeros-only\n",
        "            return \"0\"\n",
        "        return s\n",
        "    return series.apply(norm).astype(str)\n",
        "\n",
        "# ---------- Mapping spec ----------\n",
        "# kinds: \"copy\", \"concat\", \"const\", \"date\", \"sum\", \"tin_keep\"\n",
        "mapping_spec = {\n",
        "    \"Number\": (\"copy\", [\"application_id\"]),\n",
        "    \"Holder Individual\": (\"copy\", [\"client_id\"]),\n",
        "    \"Holder Entity\": (\"copy\", [\"controlling_client_id\"]),\n",
        "\n",
        "    \"First Name\": (\"copy\", [\"first_name\"]),\n",
        "    \"Last Name\":  (\"copy\", [\"last_name\"]),\n",
        "\n",
        "    # Street = address_1 + address_2\n",
        "    \"Street\": (\"concat\", [\"residential_address_1\", \"residential_address_2\"], {\"sep\": \", \"}),\n",
        "\n",
        "    \"City\": (\"copy\", [\"residential_city\"]),\n",
        "    \"Country\": (\"copy\", [\"country_of_residence\"]),\n",
        "    \"Postal Code\": (\"copy\", [\"residential_postal_code\"]),\n",
        "\n",
        "    # TIN rule: preserve exactly unless empty/NaN/zeros-only -> '0'\n",
        "    \"TIN 1\": (\"tin_keep\", [\"primary_tax_id\"]),\n",
        "    \"TIN Issuer 1\": (\"copy\", [\"primary_tax_country\"]),\n",
        "    \"Tax Residency 1\": (\"copy\", [\"primary_tax_country\"]),\n",
        "\n",
        "    # DOB -> dd/mm/YYYY\n",
        "    \"Date of Birth\": (\"date\", [\"date_of_birth\"], {\"fmt\": \"%d/%m/%Y\"}),\n",
        "\n",
        "    # Business rules\n",
        "    \"Currency\": (\"const\", \"USD\"),\n",
        "    \"Type\": (\"copy\", [\"booking_center\"]),\n",
        "    \"Number Type\": (\"copy\", [\"client_type\"]),\n",
        "\n",
        "    # Balance rule (choose one)\n",
        "    \"Balance\": (\"copy\", [\"cash_balance\"]),\n",
        "    # Or: \"Balance\": (\"sum\", [\"application_aum\", \"cash_balance\"]),\n",
        "}\n",
        "\n",
        "# ---------- Build submission in template order ----------\n",
        "submission_df = pd.DataFrame(index=raw_data.index)\n",
        "\n",
        "for tgt in required_columns:\n",
        "    spec = mapping_spec.get(tgt)\n",
        "    if not spec:\n",
        "        submission_df[tgt] = \"\"  # unmapped targets left blank\n",
        "        continue\n",
        "\n",
        "    kind = spec[0]\n",
        "    sources = spec[1] if len(spec) > 1 else []\n",
        "    opts = spec[2] if len(spec) > 2 else {}\n",
        "\n",
        "    if kind == \"copy\":\n",
        "        submission_df[tgt] = safe_series(raw_data, sources[0]).astype(str).str.strip()\n",
        "\n",
        "    elif kind == \"concat\":\n",
        "        series_list = [safe_series(raw_data, s).astype(str) for s in sources]\n",
        "        submission_df[tgt] = concat_with_sep(opts.get(\"sep\", \" \"), *series_list)\n",
        "\n",
        "    elif kind == \"const\":\n",
        "        value = spec[1] if isinstance(spec[1], str) else opts\n",
        "        submission_df[tgt] = pd.Series([value]*len(raw_data), index=raw_data.index)\n",
        "\n",
        "    elif kind == \"date\":\n",
        "        fmt = opts.get(\"fmt\", \"%d/%m/%Y\")\n",
        "        submission_df[tgt] = parse_date(safe_series(raw_data, sources[0]), fmt_out=fmt)\n",
        "\n",
        "    elif kind == \"sum\":\n",
        "        series_list = [safe_series(raw_data, s, default=0) for s in sources]\n",
        "        submission_df[tgt] = sum_numeric(*series_list).round(2)\n",
        "\n",
        "    elif kind == \"tin_keep\":\n",
        "        submission_df[tgt] = clean_tin_preserve(safe_series(raw_data, sources[0]))\n",
        "\n",
        "    else:\n",
        "        submission_df[tgt] = \"\"\n",
        "\n",
        "# Keep exact template order\n",
        "submission_df = submission_df.reindex(columns=required_columns)\n",
        "\n",
        "# ---------- Entity name rule ----------\n",
        "ENTITY_LASTNAME_TOKENS = {\n",
        "    \"PTE LTD\", \"SN ISSUER AND BROKER\", \"LIMITED\", \"FUND MANAGER\", \"ISSUER\",\n",
        "    \"CMA ACC PROVIDER\", \"COUNTERPARTY\", \"PVT MKT COUNTERPARTY\", \"CLIENT\",\n",
        "    \"HOLDING LIMITED\", \"INTERNATIONAL TRUST\"\n",
        "}\n",
        "if \"First Name\" in submission_df.columns and \"Last Name\" in submission_df.columns:\n",
        "    last_raw_norm = safe_series(raw_data, \"last_name\").astype(str).str.strip().str.upper()\n",
        "    entity_mask = last_raw_norm.isin(ENTITY_LASTNAME_TOKENS)\n",
        "    if \"Name\" in submission_df.columns:\n",
        "        fn = submission_df.get(\"First Name\", pd.Series(\"\", index=submission_df.index)).astype(str)\n",
        "        ln = submission_df.get(\"Last Name\",  pd.Series(\"\", index=submission_df.index)).astype(str)\n",
        "        full_name = concat_with_sep(\" \", fn, ln)\n",
        "        submission_df.loc[entity_mask, \"Name\"] = full_name.loc[entity_mask]\n",
        "    submission_df.loc[entity_mask, \"First Name\"] = \"\"\n",
        "    submission_df.loc[entity_mask, \"Last Name\"]  = \"\"\n",
        "\n",
        "# ---------- Joint holders counting (dtype-safe) & delete non-primary rows ----------\n",
        "if \"Number\" in submission_df.columns:\n",
        "    # Copy of original Number BEFORE filtering\n",
        "    number_orig = submission_df[\"Number\"].astype(str).str.strip()\n",
        "\n",
        "    # Identify non-empty Numbers and prefixes\n",
        "    num_nonempty = number_orig.where(number_orig.ne(\"\"), pd.NA)\n",
        "    starts_J = number_orig.str.upper().str.startswith(\"J\")\n",
        "    starts_S = number_orig.str.upper().str.startswith(\"S\")\n",
        "\n",
        "    # Count identical Number IDs (ignoring blanks)\n",
        "    group_counts = num_nonempty.groupby(num_nonempty).transform(\"size\")\n",
        "    group_counts = pd.Series(group_counts, index=submission_df.index).astype(\"Int64\")\n",
        "\n",
        "    # Build an Int64 series: default 1, J* -> group size, S* -> NA (blank later)\n",
        "    joint_vals = pd.Series(1, index=submission_df.index, dtype=\"Int64\")\n",
        "    joint_vals = joint_vals.mask(starts_J & num_nonempty.notna(), group_counts)\n",
        "    joint_vals = joint_vals.mask(starts_S, pd.NA)\n",
        "\n",
        "    # Decide the output column name\n",
        "    joint_col = next((c for c in [\"Nr Joint Holders\", \"Joint Holders\"] if c in submission_df.columns),\n",
        "                     \"Nr Joint Holders\")\n",
        "    # Assign the Int64 series first\n",
        "    submission_df[joint_col] = joint_vals\n",
        "\n",
        "    # DELETE rows that are not primary_client_id\n",
        "    if \"Number Type\" in submission_df.columns:\n",
        "        keep_mask = submission_df[\"Number Type\"].astype(str).str.strip().str.lower().eq(\"primary_client_id\")\n",
        "        submission_df = submission_df.loc[keep_mask].copy()\n",
        "\n",
        "    # Convert <NA> to empty strings for Excel display\n",
        "    submission_df[joint_col] = submission_df[joint_col].astype(\"object\").where(\n",
        "        submission_df[joint_col].notna(), \"\"\n",
        "    )\n",
        "\n",
        "# ---------- Optional: Is Joint? flag (if present) ----------\n",
        "if \"Is Joint?\" in submission_df.columns:\n",
        "    src_now = submission_df.get(\"Number\", pd.Series(\"\", index=submission_df.index)).astype(str)\n",
        "    submission_df[\"Is Joint?\"] = np.where(src_now.str.upper().str.startswith(\"J\"), \"T\", \"F\")\n",
        "\n",
        "# ---------- Optional clean-ups ----------\n",
        "# SG postal code normalize\n",
        "if \"Postal Code\" in submission_df.columns:\n",
        "    submission_df[\"Postal Code\"] = (\n",
        "        submission_df[\"Postal Code\"].astype(str)\n",
        "        .str.replace(r\"\\D\", \"\", regex=True)\n",
        "        .str.zfill(6)\n",
        "    )\n",
        "\n",
        "# ---------- Save ----------\n",
        "out_path = 'submission_ready.xlsx'\n",
        "submission_df.to_excel(out_path, index=False)\n",
        "print(f\"Saved: {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHyfjdTJbq_6",
        "outputId": "e7e693e2-0ec5-415a-95a4-a6338ec283b6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: submission_ready.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding more Last Name tokens (using REGEX) for KASG entity\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ---------- Paths ----------\n",
        "raw_path = '/content/crs_export_KASG.xlsx'\n",
        "template_path = '/content/KAMEL - CRS Submission.xlsx'\n",
        "\n",
        "# ---------- Load data ----------\n",
        "raw_data = pd.read_excel(raw_path, sheet_name=0)\n",
        "# If the template has a title row above headers, header=1 captures the real headers\n",
        "template  = pd.read_excel(template_path, sheet_name='Accounts', header=1)\n",
        "required_columns = list(template.columns)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def safe_series(df, col, default=\"\"):\n",
        "    return df[col] if col in df.columns else pd.Series([default] * len(df), index=df.index)\n",
        "\n",
        "def concat_with_sep(sep, *series_list):\n",
        "    parts = []\n",
        "    for s in series_list:\n",
        "        s_clean = s.astype(str).str.strip().replace({\"nan\": \"\", \"None\": \"\"})\n",
        "        s_clean = s_clean.mask(s_clean.eq(\"\"))  # empty -> NaN\n",
        "        parts.append(s_clean)\n",
        "    stacked = pd.concat(parts, axis=1)\n",
        "    return stacked.apply(lambda r: sep.join([x for x in r.dropna().astype(str)]), axis=1).fillna(\"\")\n",
        "\n",
        "def sum_numeric(*series_list):\n",
        "    total = pd.Series(0.0, index=series_list[0].index, dtype=\"float64\")\n",
        "    for s in series_list:\n",
        "        total = total.add(pd.to_numeric(s, errors=\"coerce\").fillna(0.0), fill_value=0.0)\n",
        "    return total\n",
        "\n",
        "def parse_date(series, fmt_out=\"%d/%m/%Y\"):\n",
        "    parsed = pd.to_datetime(series, errors=\"coerce\")\n",
        "    out = pd.Series(\"\", index=series.index, dtype=\"object\")\n",
        "    mask = parsed.notna()\n",
        "    out.loc[mask] = parsed.loc[mask].dt.strftime(fmt_out)\n",
        "    out.loc[~mask] = series.astype(str).where(~series.isna(), \"\")\n",
        "    return out\n",
        "\n",
        "def clean_tin_preserve(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Preserve TIN exactly unless it is empty/NaN or all zeros -> '0'.\n",
        "    Handles numeric-looking inputs like 12345.0 -> '12345'.\n",
        "    \"\"\"\n",
        "    def norm(v):\n",
        "        if pd.isna(v):\n",
        "            return \"0\"\n",
        "        if isinstance(v, (int, np.integer)):\n",
        "            s = str(v)\n",
        "        elif isinstance(v, float):\n",
        "            if np.isfinite(v) and v.is_integer():\n",
        "                s = str(int(v))\n",
        "            else:\n",
        "                s = str(v)\n",
        "        else:\n",
        "            s = str(v)\n",
        "        s = s.strip()\n",
        "        if s == \"\" or s.lower() in (\"nan\", \"none\"):\n",
        "            return \"0\"\n",
        "        if len(s) > 0 and set(s) <= {\"0\"}:  # zeros-only\n",
        "            return \"0\"\n",
        "        return s\n",
        "    return series.apply(norm).astype(str)\n",
        "\n",
        "# Normalize for matching: uppercase, punctuation -> space, collapse spaces\n",
        "def norm_for_regex(series: pd.Series) -> pd.Series:\n",
        "    s = series.astype(str).str.upper()\n",
        "    s = s.str.replace(r\"[^\\w\\s]\", \" \", regex=True)\n",
        "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "    return s\n",
        "\n",
        "# ---------- Mapping spec ----------\n",
        "# kinds: \"copy\", \"concat\", \"const\", \"date\", \"sum\", \"tin_keep\"\n",
        "mapping_spec = {\n",
        "    \"Number\": (\"copy\", [\"application_id\"]),\n",
        "    \"Holder Individual\": (\"copy\", [\"client_id\"]),\n",
        "    \"Holder Entity\": (\"copy\", [\"controlling_client_id\"]),\n",
        "\n",
        "    \"First Name\": (\"copy\", [\"first_name\"]),\n",
        "    \"Last Name\":  (\"copy\", [\"last_name\"]),\n",
        "\n",
        "    # Street = address_1 + address_2\n",
        "    \"Street\": (\"concat\", [\"residential_address_1\", \"residential_address_2\"], {\"sep\": \", \"}),\n",
        "\n",
        "    \"City\": (\"copy\", [\"residential_city\"]),\n",
        "    \"Country\": (\"copy\", [\"country_of_residence\"]),\n",
        "    \"Postal Code\": (\"copy\", [\"residential_postal_code\"]),\n",
        "\n",
        "    # TIN rule: preserve exactly unless empty/NaN/zeros-only -> '0'\n",
        "    \"TIN 1\": (\"tin_keep\", [\"primary_tax_id\"]),\n",
        "    \"TIN Issuer 1\": (\"copy\", [\"primary_tax_country\"]),\n",
        "    \"Tax Residency 1\": (\"copy\", [\"primary_tax_country\"]),\n",
        "\n",
        "    # DOB -> dd/mm/YYYY\n",
        "    \"Date of Birth\": (\"date\", [\"date_of_birth\"], {\"fmt\": \"%d/%m/%Y\"}),\n",
        "\n",
        "    # Business rules\n",
        "    \"Currency\": (\"const\", \"USD\"),\n",
        "    \"Type\": (\"copy\", [\"booking_center\"]),\n",
        "    \"Number Type\": (\"copy\", [\"client_type\"]),\n",
        "\n",
        "    # Balance rule (choose one)\n",
        "    \"Balance\": (\"copy\", [\"cash_balance\"]),\n",
        "    # Or: \"Balance\": (\"sum\", [\"application_aum\", \"cash_balance\"]),\n",
        "}\n",
        "\n",
        "# ---------- Build submission in template order ----------\n",
        "submission_df = pd.DataFrame(index=raw_data.index)\n",
        "\n",
        "for tgt in required_columns:\n",
        "    spec = mapping_spec.get(tgt)\n",
        "    if not spec:\n",
        "        submission_df[tgt] = \"\"  # unmapped targets left blank\n",
        "        continue\n",
        "\n",
        "    kind = spec[0]\n",
        "    sources = spec[1] if len(spec) > 1 else []\n",
        "    opts = spec[2] if len(spec) > 2 else {}\n",
        "\n",
        "    if kind == \"copy\":\n",
        "        submission_df[tgt] = safe_series(raw_data, sources[0]).astype(str).str.strip()\n",
        "\n",
        "    elif kind == \"concat\":\n",
        "        series_list = [safe_series(raw_data, s).astype(str) for s in sources]\n",
        "        submission_df[tgt] = concat_with_sep(opts.get(\"sep\", \" \"), *series_list)\n",
        "\n",
        "    elif kind == \"const\":\n",
        "        value = spec[1] if isinstance(spec[1], str) else opts\n",
        "        submission_df[tgt] = pd.Series([value] * len(raw_data), index=raw_data.index)\n",
        "\n",
        "    elif kind == \"date\":\n",
        "        fmt = opts.get(\"fmt\", \"%d/%m/%Y\")\n",
        "        submission_df[tgt] = parse_date(safe_series(raw_data, sources[0]), fmt_out=fmt)\n",
        "\n",
        "    elif kind == \"sum\":\n",
        "        series_list = [safe_series(raw_data, s, default=0) for s in sources]\n",
        "        submission_df[tgt] = sum_numeric(*series_list).round(2)\n",
        "\n",
        "    elif kind == \"tin_keep\":\n",
        "        submission_df[tgt] = clean_tin_preserve(safe_series(raw_data, sources[0]))\n",
        "\n",
        "    else:\n",
        "        submission_df[tgt] = \"\"\n",
        "\n",
        "# Keep exact template order\n",
        "submission_df = submission_df.reindex(columns=required_columns)\n",
        "\n",
        "# ---------- Entity name rule via REGEX ----------\n",
        "# Build a *single* combined regex. We match on normalized (punctuation-stripped) text.\n",
        "# Each subpattern is designed to match full tokens or *company-style suffixes* at line end.\n",
        "ENTITY_REGEX_PATTERNS = [\n",
        "    r'\\bSN\\s+ISSUER\\s+AND\\s+BROKER\\b$',\n",
        "    r'\\bFUND\\s+MANAGER\\b$',\n",
        "    r'\\bISSUER\\b$',\n",
        "    r'\\bCMA\\s+ACC\\s+PROVIDER\\b$',\n",
        "    r'\\bPVT\\s+MKT\\s+COUNTERPARTY\\b$',\n",
        "    r'\\bCOUNTERPARTY\\b$',\n",
        "    r'\\bCLIENT\\b$',\n",
        "    r'\\bINTERNATIONAL\\s+TRUST\\b$',\n",
        "    r'\\bHOLDING\\s+LIMITED\\b$',\n",
        "\n",
        "    # Common company suffixes & your examples\n",
        "    r'\\bBANK\\s+OF\\s+SINGAPORE\\s+LTD\\b$',\n",
        "    r'\\bHOLDINGS?\\s+GLOBAL\\s+LTD\\b$',\n",
        "    r'\\bSUMMIT\\s+INVESTMENTS\\s+LTD\\b$',\n",
        "    r'\\bPRIMELINK\\s+LTD\\b$',\n",
        "    r'\\bHOLDINGS?\\s+INC\\b$',\n",
        "    r'\\bHOLDINGS?\\s+LTD\\b$',\n",
        "    r'\\bINVESTMENTS?\\s+(?:PTE\\s+|PTY\\s+)?LTD\\b$',\n",
        "    r'\\bINNOVATIONS?\\s+(?:PTE\\s+)?LTD\\b$',\n",
        "    r'\\bTRADING\\s+(?:PTE\\s+)?LTD\\b$',\n",
        "    r'\\bSINGAPORE\\s+PTE\\s+LTD\\b$',\n",
        "    r'\\bINC\\s+PTE\\s+LTD\\b$',\n",
        "    r'\\bPTE\\s+LTD\\b$',       # PTE LTD variations after normalization\n",
        "    r'\\bPTY\\s+LTD\\b$',\n",
        "    r'\\bLTD\\b$'\n",
        "]\n",
        "\n",
        "ENTITY_REGEX_COMBINED = r'(?:' + '|'.join(ENTITY_REGEX_PATTERNS) + r')'\n",
        "# Normalize RAW last_name and test\n",
        "last_raw_norm = norm_for_regex(safe_series(raw_data, \"last_name\"))\n",
        "entity_mask = last_raw_norm.str.contains(ENTITY_REGEX_COMBINED, regex=True, na=False)\n",
        "\n",
        "# If \"Name\" exists, set it to \"First Name + Last Name\" for entity rows\n",
        "if \"Name\" in submission_df.columns:\n",
        "    fn = submission_df.get(\"First Name\", pd.Series(\"\", index=submission_df.index)).astype(str)\n",
        "    ln = submission_df.get(\"Last Name\",  pd.Series(\"\", index=submission_df.index)).astype(str)\n",
        "    full_name = concat_with_sep(\" \", fn, ln)\n",
        "    submission_df.loc[entity_mask, \"Name\"] = full_name.loc[entity_mask]\n",
        "\n",
        "# Blank First/Last for entity rows\n",
        "if \"First Name\" in submission_df.columns:\n",
        "    submission_df.loc[entity_mask, \"First Name\"] = \"\"\n",
        "if \"Last Name\" in submission_df.columns:\n",
        "    submission_df.loc[entity_mask, \"Last Name\"]  = \"\"\n",
        "\n",
        "# ---------- Joint holders counting (dtype-safe) & delete non-primary rows ----------\n",
        "if \"Number\" in submission_df.columns:\n",
        "    # Copy of original Number BEFORE filtering (for counts)\n",
        "    number_orig = submission_df[\"Number\"].astype(str).str.strip()\n",
        "\n",
        "    # Identify non-empty Numbers and prefixes\n",
        "    num_nonempty = number_orig.where(number_orig.ne(\"\"), pd.NA)\n",
        "    starts_J = number_orig.str.upper().str.startswith(\"J\")\n",
        "    starts_S = number_orig.str.upper().str.startswith(\"S\")\n",
        "\n",
        "    # Count identical Number IDs (ignoring blanks)\n",
        "    group_counts = num_nonempty.groupby(num_nonempty).transform(\"size\")\n",
        "    group_counts = pd.Series(group_counts, index=submission_df.index).astype(\"Int64\")\n",
        "\n",
        "    # Build an Int64 series: default 1, J* -> group size, S* -> NA (blank later)\n",
        "    joint_vals = pd.Series(1, index=submission_df.index, dtype=\"Int64\")\n",
        "    joint_vals = joint_vals.mask(starts_J & num_nonempty.notna(), group_counts)\n",
        "    joint_vals = joint_vals.mask(starts_S, pd.NA)\n",
        "\n",
        "    # Output column name (use template's if present; else create \"Nr Joint Holders\")\n",
        "    joint_col = next((c for c in [\"Nr Joint Holders\", \"Joint Holders\"] if c in submission_df.columns),\n",
        "                     \"Nr Joint Holders\")\n",
        "    submission_df[joint_col] = joint_vals\n",
        "\n",
        "    # DELETE rows that are not primary_client_id\n",
        "    if \"Number Type\" in submission_df.columns:\n",
        "        keep_mask = submission_df[\"Number Type\"].astype(str).str.strip().str.lower().eq(\"primary_client_id\")\n",
        "        submission_df = submission_df.loc[keep_mask].copy()\n",
        "\n",
        "    # Convert <NA> to \"\" for Excel display\n",
        "    submission_df[joint_col] = submission_df[joint_col].astype(\"object\").where(\n",
        "        submission_df[joint_col].notna(), \"\"\n",
        "    )\n",
        "\n",
        "# ---------- Optional: Is Joint? flag (if present) ----------\n",
        "if \"Is Joint?\" in submission_df.columns:\n",
        "    src_now = submission_df.get(\"Number\", pd.Series(\"\", index=submission_df.index)).astype(str)\n",
        "    submission_df[\"Is Joint?\"] = np.where(src_now.str.upper().str.startswith(\"J\"), \"T\", \"F\")\n",
        "\n",
        "# ---------- Optional clean-ups ----------\n",
        "# SG postal code normalize\n",
        "if \"Postal Code\" in submission_df.columns:\n",
        "    submission_df[\"Postal Code\"] = (\n",
        "        submission_df[\"Postal Code\"].astype(str)\n",
        "        .str.replace(r\"\\D\", \"\", regex=True)\n",
        "        .str.zfill(6)\n",
        "    )\n",
        "\n",
        "# ---------- Save ----------\n",
        "out_path = 'submission_ready.xlsx'\n",
        "submission_df.to_excel(out_path, index=False)\n",
        "print(f\"Saved: {out_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1oSec3qiDVM",
        "outputId": "53ac2796-1de0-445e-d113-4cc03b32b472"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: submission_ready.xlsx\n"
          ]
        }
      ]
    }
  ]
}